% 6. Ataque usando algoritmos genéticos. 
% El ataque está basado en el cálculo de la distancia de un código. 
% Lo puedes encontrar en el archivo Cuellar_etal_2021.pdf (es un algoritmo genético muy sencillo). 
% Implementación en Sagemath de un supuesto ataque, a ver hasta que longitud puedes cargártelo (como mucho 512, la verdad)
\chapter{Ataque usando algoritmos genéticos}

En el capítulo \ref{cap:2} vimos que la capacidad de corrección de un código depende de la distancia de un código. Sin embargo, encontrar una palabra con distancia mínima de un código lineal no es una tarea fácil. Recordemos que el problema de decisión asociado al cálculo de la distancia mínima de un código lineal binario es NP-completo. 

En esta sección estudiaremos varios ataques usando algoritmos genéticos basados en el cálculo de la distancia de un código propuestos en \cite{Cuellar_etal}. Probaremos que, dada una matriz generadora, existe una permutación de las columnas cuya matriz escalonada contiene una fila cuyo peso es la distancia del código. Los algoritmos trabajarán con un espacio de soluciones igual al conjunto de posibles permutaciones de las columnas de la matriz generadora. En concreto, adaptaremos e implementaremos algoritmos genéticos generacionales (GGA) y CHC para revolver este problema.

\section{Esquema basado en permutaciones}
\label{sec:perm}

Sea $\mathbb{F}_q$ un cuerpo finito con $q$ elementos y sean $k,n$ dos números enteros tales que $0 < k \leq n$. Denotamos por $\mathcal{S}_n$ al conjunto de permutaciones de $n$ símbolos. Decimos que dos $[n, k]_q$-códigos lineales $\mathcal{C}_1$ y $\mathcal{C}_2$ son \emph{equivalentes permutacionalmente} si son iguales con una permutación fija de las coordenadas de una palabra código, esto es, si existe una permutación $x \in \mathcal{S}_n$ tal que $(c_0, ..., c_{n-1}) \in \mathcal{C}_1$ si y solo si $(c_{x(0)}, ..., c_{x(n-1)}) \in \mathcal{C}_2$. Observemos que $G$ es la matriz generadora de $\mathcal{C}_1$ si y solo si $GP$ es la matriz generadora de $\mathcal{C}_2$, donde $P$ es la matriz asociada a la permutación $x$. Los códigos equivalentes permutacionalmente tienen en común la distancia mínima, ya que la permutación de sus componentes no modifica el peso del vector.

El siguiente resultado nos proporciona un método para calcular la distancia mínima a partir de la matriz escalonada (\emph{reduced row echelon form}) de la matriz generadora del código equivalente.

\begin{theorem}
    Sea $G$ una matriz generadora de dimensión $k \times n$ de un $[n, k]_q$-código lineal $\mathcal{C}$ sobre el cuerpo finito $\mathbb{F}_q$. Existe una permutación $x \in \mathcal{S}_n$ tal que la matriz escalonada, $R$, de $GP_x$, donde $P_x$ es la matriz asociada a la permutación $x$, cumple que el peso de alguna de sus filas alcanza la distancia mínima de $\mathcal{C}$. Por lo tanto, si $b$ es una fila de $R$ verificando esa propiedad, entonces $bP_x^{-1}$ es una palabra código no nula de $\mathcal{C}$ con peso mínimo.
\end{theorem}

\begin{proof}
    Sea $d$ la distancia mínima de $\mathcal{C}$ y sea $a \in \mathcal{C}$ una palabra código tal que $w(a) = d$. Como $a$ es distinto de cero, existe una matriz regular $A$ de dimensión $k \times k$ sobre $\mathbb{F_q}$ tal que 
    \[
        AG = \left( \frac{G_1}{a} \right)
    \]
    para alguna matriz $G_1$ de dimensión $(k-1) \times n$ sobre $\mathbb{F_q}$. Por otra parte, como $w(a) = d$, existe una permutación $x \in \mathcal{S}_n$ que mueve las entradas no nulas de $a$ a las últimas posiciones, esto es,
    \[
        aP_x = (0, ..., 0, a_1, ..., a_d),
    \]
    donde $a_1, ..., a_d \in \mathbb{F}_q \backslash \{ 0 \}$. Luego
    \[
        AGP_x = \left( \frac{G_1 P_x}{a P_x} \right) = \left( \frac{G_1 P_x}{0 \cdots 0 \vert a_1 \cdots a_d} \right).
    \]
    Ahora, definimos la matriz $A'$ de dimensión $(k-1) \times (k-1)$ sobre $\mathbb{F_q}$ de tal forma que sea invertible y que $A'G_1P_x = H'$ sea una matriz escalonada. Tenemos que
    \begin{equation}
        \label{eq:matriz_bloques}
        \left( 
            \begin{array}{c|c} 
                A' & 0 \\
                \hline
                0 & 1
            \end{array}
        \right)
        AGP_x
        =
        \left( 
            \begin{array}{c|c} 
                A' & 0 \\
                \hline
                0 & 1
            \end{array}
        \right)
        \left( 
            \begin{array}{c} 
                G_1P_x \\
                \hline
                \begin{array}{c|c}
                    0 \cdots 0 & a_1 \cdots a_d
                \end{array}
            \end{array}
        \right)
        = 
        \left( 
            \begin{array}{c} 
                H' \\
                \hline
                \begin{array}{c|c}
                    0 \cdots 0 & a_1 \cdots a_d
                \end{array}
            \end{array}
        \right).
    \end{equation}
    La última fila de $H'$ es distinta de cero, pues la matriz $G_1$ tiene rango $k-1$. Supongamos que el pivote de esta fila está en la columna $i_0$-ésima. Supongamos que $i_0 \geq n - d + 1$, entonces las últimas dos filas de \eqref{eq:matriz_bloques} son linealmente independientes y las coordenadas no nulas se encuentran en las últimas $d$ coordenadas. Por tanto, existe una combinación lineal de ambas cuyo peso es menor que $d$, lo que lleva a una contradicción. Luego se tiene que $i_0 < n - d + 1$ y en consecuencia, la última fila de \eqref{eq:matriz_bloques} coincide con la última fila de la matriz escalonada de $GP_x$, salvo multiplicación escalar no nula, como queríamos.
\end{proof}

Este teorema expone que encontrar la distancia mínima de un $[n, k]_q$-código lineal se reduce a encontrar el mínimo de la aplicación $\mathfrak d : \mathcal{S}_n \rightarrow \mathbb{N}$ definida por
\[
    \mathfrak d (x) = \min \left\{ \text{w}(b) \; : \; b \text{ es una fila de la matriz escalonada de } FP_x \right\}
\]
para cualquier $x \in \mathcal{S}_n$, donde $G$ es la matriz generadora del código y $P_x$ representa la matriz asociada a la permutación $x$.

Sin embargo, existen pocas permutaciones que nos proporcionarán el mínimo de $\mathfrak{d}$. En concreto, supongamos que solo hay una palabra código que alcanza el mínimo peso $d$ de $\mathcal{C}$ salvo multiplicación escalar.

En \cite{Cuellar_etal} se obtiene que la probabilidad de encontrar el mínimo de $\mathfrak{d}$ por una búsqueda aleatoria es
\[
    \frac{d! (n-d)!}{n!} = {n \choose d}^{-1}.
\]

\begin{exampleth}
    Vamos a ilustrar el esquema descrito para obtener el peso mínimo de un código a partir de su matriz escalonada. Sea $\mathcal{C}$ un $[8, 4]_4$-código lineal sobre el cuerpo finito $\mathbb{F}_4 = \{ 0, 1, a, a + 1 \}$ con matriz generadora
    \[ G =
        \left(
        \begin{array}{cccccccc} 
            1 & 0 & a+1 & a+1 & a+1 & 0 & 0 & a  \\
            a+1 & 0 & 0 & a+1 & a & a+1 & 1 & a+1  \\
            1 & a+1 & 1 & a+1 & a & 0 & a & 0  \\
            0 & 0 & 0 & a & a & a & a+1 & a
        \end{array}
        \right).
    \]
    Sea $x \in \mathcal{S}_8$ la permutación dada por $x(0) = 1$, $x(1) = 0$, $x(2) = 3$, $x(3) = 2$, $x(4) = 5$, $x(5) = 4$, $x(6) = 7$ y $x(7) = 6$. La matriz asociada a la permutación $x$ es la siguiente:
    \[ P_x =
        \left(
        \begin{array}{cccccccc} 
            0 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\
            1 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
            0 & 0 & 0 & 1 & 0 & 0 & 0 & 0  \\
            0 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\
            0 & 0 & 0 & 0 & 0 & 1 & 0 & 0  \\
            0 & 0 & 0 & 0 & 1 & 0 & 0 & 0  \\
            0 & 0 & 0 & 0 & 0 & 0 & 0 & 1  \\
            0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 
        \end{array}
        \right).
    \]
    Aplicamos esta permutación a la matriz generadora $G$ para obtener la matriz generadora $G^x$ del código equivalente permutacionalmente $\mathcal{C}_x$:
    \[ G^x =
        \left(
        \begin{array}{cccccccc} 
            0 & 1 & a+1 & a+1 & 0 & a+1 & a & 0  \\
            0 & a+1 & a+1 & 0 & a+1 & a & a+1 & 1  \\
            a+1 & 1 & a+1 & 1 & 0 & a & 0 & a  \\
            0 & 0 & a & 0 & a & a & a & a+1
        \end{array}
        \right).
    \]
    La matriz escalonada de $G^x$ es
    \[ G^x =
        \left(
        \begin{array}{cccccccc} 
            1 & 0 & 0 & 0 & a+1 & 0 & a & a  \\
            0 & 1 & 0 & 0 & 0 & a & 0 & 0  \\
            0 & 0 & 1 & 0 & 1 & 1 & 1 & a  \\
            0 & 0 & 0 & 1 & 1 & a+1 & a & a
        \end{array}
        \right),
    \]
    donde el peso de la primera fila es $4$, el de la segunda es $2$ y el de la tercera y cuarta es $5$. Como la segunda fila tiene peso mínimo entre todas las filas, tenemos que $\mathfrak{d} (x) = 2$. Realmente, la distancia de $\mathcal{C}$ es $2$, luego $x$ alcanza el mínimo de $\mathfrak{d}$.
\end{exampleth}

\section{Algoritmos genéticos}

En esta sección estudiaremos las adaptaciones de los algoritmos GGA y CHC propuestos en \cite{Cuellar_etal} para resolver el problema de encontrar la distancia mínima de un código lineal. Además, implementaremos ambos algoritmos y analizaremos los resultados.

La representación clásica de estos algoritmos es la discreta. Esto es, fijado un código $\mathcal{C}$ de longitud $n$ y dimensión $k$ sobre un cuerpo finito con $q$ elementos $\mathbb{F}_q$, consideramos su matriz generadora $G$. Buscaremos una $k$-tupla $m = (m_1, ..., m_k) \in \mathbb{F}_q^k$ con $m \neq 0$ de tal forma que el peso correspondiente a la palabra código $mG$ sea mínimo. De este modo, cada solución (cromosoma) $x$ estará asignada a un mensaje $m$ como un fenotipo, mientras que los genotipos se componen de $k$ variables de decisión o genes cuyos valores están en el conjunto $\mathbb{F}_q$. De esta forma, la función fitness definida en $\mathbb{F}_q^k \longrightarrow \mathbb{N}$ consistirá en minimizar el peso que producen las soluciones que componen la población.

No obstante, según el resultado de la sección \ref{sec:perm} podemos cambiar el espacio de las soluciones del planteamiento tradicional del problema al espacio de las permutaciones de $n$ elementos, $\mathcal{S}_n$, donde $n$ es la longitud del código lineal que estudiaremos. Esto tiene una consecuencia inmediata: nos permite cambiar el problema de encontrar la distancia mínima $d(\mathcal{C})$ de un código $\mathcal{C}$, para que la búsqueda de la palabra código con peso mínimo equivalga a encontrar una permutación $x \in \mathcal{S}_n$ adecuada de las columnas de una matriz generadora de tal forma que la fila $r$ de su matriz escalonada tenga peso $w(r) = d(\mathcal{C})$. Así, las soluciones (cromosomas) se representarán como permutaciones $x$ (fenotipos) de las $n$ columnas de la matriz generadora $G$, y que contienen $n$ variables de decisión (genotipos) cuyos valores pueden ser $\{ 1,...,n\}$, donde cada número representa una posición de cada columna de la matriz. Esto es, dada una permutación $x = (x_1, ..., x_n)$, un valor $x_i$ significa que la columna de la matriz que se encuentra en la posición $i$ cambiará su ubicación a la columna en la posicición $x_i$ en la permutación.

Por tanto, el fitness de una permutación $x \in \mathcal{S}_n$ se puede calcular como
\[
    f(x) = \min \{w(r_i) : r_i \text{ es una fila de la matriz escalonada de } GP_x \},
\]
donde $P_x$ denota a la matriz de permutaciones de $x$.

\subsection{Algoritmo GGA}

El algoritmo GGA comienza con la inicialización de la población $P(t)$ con $N$ soluciones aleatorias y las evalúa en la iteración $t = 0$. Luego, el principal bucle del algoritmo se ejecuta hasta que se cumpla la condición de parada, que en este caso será un número máximo de generaciones. 

El bucle principal empieza seleccionando $N$ padres según el operador de selección de torneo binario. Este operador consiste en seleccionar dos individuos de la población aleatorios y seleccionar como padre al individuo que tenga mejor fitness.

Después, comienza la etapa de generación de una nueva población. De esta forma, se le aplica el operador de cruce a dos padres elegidos aleatoriamente para generar un nuevo par de soluciones con probabilidad $p_c$. Este operador consiste en componer ambos padres, es decir, sean $p_1$ y $p_2$ dos padres, el operador de cruce generará dos descencientes $d_1$ y $d_2$ a partir de la composición de cada uno en distintos órdenes:
\[
    d_1 = p_1 \circ p_2,
\]
\[
    d_2 = p_2 \circ p_1.
\]
Si no se combinan, se le aplica el operador de mutación a cada padre para generar una solución mutada. Este operador elige una columna de las primeras $k$ columnas y otra de las $n-k$ columnas restantes de la matriz generadora y las permuta para crear un nuevo descendiente.

En ambos casos, habrá que comprobar que las nuevas soluciones son válidas. Esto es, una solución no válida en el algoritmo GGA es la solución nula $(0,...,0)$. De esta forma, todas las nuevas soluciones $N$ se habrán generado por cruce o mutación y formarán la población de la siguiente iteración $P(t+1)$. Finalmente, se evalúan las soluciones de $P(t+1)$.

Se ha incluído una componente elitista antes de que comience la siguiente iteración: si la solución $P(t+1)$ no tiene un fitness igual o superior que la mejor en $P(t)$, entonces la peor solución de $P(t+1)$ es reemplazada por la mejor solución de $P(t)$. Además, si se alcanza un número fijo de evaluaciones de las soluciones que no producen mejora en el fitness de la mejor solución encontrada, se reiniciará $P(t+1)$ con $N$ nuevas soluciones aleatorias.

En resumen, el Algoritmo GGA consiste en:

\begin{Ualgorithm}[H]
    \DontPrintSemicolon
    \KwIn{$N$: número par con el tamaño de la población}
    \KwIn{$p_c$: probabilidad de cruce}
    \KwIn{$max\_reinit$: número de evaluaciones de las soluciones sin mejorar el fitness antes de la reinicialización}
    \KwOut{Mejor solución de $P(t)$}
    
    $t \longleftarrow 0$\;
    Inicializar la población $P(t)$ con $N$ soluciones aleatorias válidas\;
    Evaluar las soluciones de $P(t)$\;
    
    \While{no se cumpla la condición de parada}{
        $P(t+1) \longleftarrow \emptyset$\;
        $padres(1, ..., N) \longleftarrow$ Seleccionar $N$ soluciones de $P(t)$ con selección de torneo binario\;
        
        \For{$i$ in $0..N/2 - 1$}{
            \eIf{número aleatorio de la distribución uniforme $[0,1]$ es menor que $p_c$}{
                $c_1, c_2 \longleftarrow$ soluciones generadas a partir del cruce de los padres $padres(2i)$ y $padres(2i + 1)$\;
            }
            {
                $c_1 \longleftarrow$ mutación del padre $padres(2i)$\;
                $c_2 \longleftarrow$ mutación del padre $padres(2i + 1)$\;
            }
            \If{$c_1$ (resp. $c_2$) no es válido}{
                reemplazar $c_1$ (resp. $c_2$) con una solución aleatoria válida\;
            }
            $P(t+1) \longleftarrow P(t+1) \bigcup \{ c_1, c_2 \}$\;
        }
        
        Evaluar las soluciones de $P(t+1)$\;
        
        \If{ningún fitness de $P(t+1)$ es igual o superior que el mejor fitness de $P(t)$}{
            Reemplazar la peor solución de $P(t+1)$ con la mejor solución de $P(t)$\;
        }
        
        \If{max\_reinit soluciones han sido evaluadas sin mejorar la mejor solución de $P(t+1)$}{
            Reemplazar las soluciones de $P(t+1)$ con $N-1$ soluciones aleatorias y la mejor solución de $P(t)$\;
        }
        
        $t \longleftarrow t + 1$\;
    }
    \caption{Algoritmo GGA.}
\end{Ualgorithm}

\subsection{Algoritmo CHC}

El algoritmo CHC es un algoritmo evolutivo cuya versión inicial fue propuesta para codificación binaria \cite{CHC_1991}. Este algoritmo mantiene un equilibrio entre la diversidad de los genotipos en las soluciones de la población y la convergencia a óptimos locales. Se basa en cuatro componentes similares: la selección elitista, el operador de recombinador de soluciones HUX, una verificación de prevención de incesto para evitar la recombinación de soluciones similares y un método de reiniciación de la población cuando se encuentra un óptimo local. En \cite{Cuellar_etal} se propone una adaptación de este algoritmo, que es la que vamos a estudiar.

Para calcular la distancia entre dos soluciones de la población usaremos la distancia de Hamming (líneas 4-5 y 22-23 del algoritmo \ref{alg:CHC}). En cuanto al decremento $dec$ del cruce (líneas 5 y 21), se actualiza como un porcentaje $\tau$ de la máxima distancia de Hamming entre los individuos de la población, donde $\tau \in [0,1]$ es la tasa de actualización, un parámetro de entrada al algoritmo. Si se produce una solución no válida en el cruce, se le asignará un fitness igual a infinito para asegurarnos de que no se incluirá en la población de la siguiente generación.

El algoritmo CHC comienza con la inicialización de la población $P(t)$ con $N$ soluciones aleatorias y las evalúa en la iteración $t = 0$. Luego, se calcula la distancia media y la máxima entre todas las soluciones. Así, la variable $d$ se inicializará a la distancia media y $dec$ se inicializará a la máxima distancia multiplicada por $\tau$. Luego, el principal bucle del algoritmo se ejecuta hasta que se cumpla la condición de parada, que en este caso será un número máximo de generaciones.

El bucle principal empieza seleccionando $N$ padres aleatorios entre las soluciones de $P(t)$.

Después, comienza la etapa de generación de una nueva población. De esta forma, se le aplica el operador de cruce a los padres que estén a una distancia menor que el umbral de distancia $d$. Este operador es análogo al operador de cruce del algoritmo GGA. Una vez generados todos los descendientes, se evaluarán. A continuación, se formará la población de la siguiente iteración $P(t+1)$ que contendrá a $N$ individuos, escogidos entre las mejores soluciones de $P(t)$ y las nuevas soluciones generadas por el cruce. Sin embargo, puede que $P(t+1)$ y $P(t)$ sean iguales, en este caso el umbral de distancia $d$ se decrementa en $dec$. Si este umbral $d$ alcanza un valor negativo o nulo, la población se reinicializará. Para ello, conservaremos la mejor solución de $P(t)$ en la siguiente población y el resto la reemplazaremos por $N-1$ soluciones aleatorias. Los valores $d$ y $dec$ se recalcularán para esta nueva población.

En resumen, el Algoritmo CHC consiste en:

\begin{Ualgorithm}[H]
    \label{alg:CHC}
    \DontPrintSemicolon
    \KwIn{$N$: número par con el tamaño de la población}
    \KwIn{$\tau$: frecuencia de actualización del umbral de cruce}
    \KwOut{Mejor solución de $P(t)$}
    
    $t \longleftarrow 0$\;
    Inicializar la población $P(t)$ con $N$ soluciones aleatorias válidas\;
    Evaluar las soluciones de $P(t)$\;
    $d \longleftarrow$ Media de la distancia de las soluciones de $P(t)$\;
    $dec \longleftarrow \tau \cdot$ Distancia máxima de las soluciones de $P(t)$\;

    \While{no se cumpla la condición de parada}{
        $C(t) \longleftarrow \emptyset$\;
        $padres(1, ..., N) \longleftarrow$ Seleccionar $N$ soluciones aleatorias de $P(t)$\;
        
        \For{$i$ in $0..N/2 - 1$}{
            \If{$distancia(padres(2i), padres(2i + 1)) < d$}{
                $c_1, c_2 \longleftarrow$ soluciones generadas a partir del cruce de los padres $padres(2i)$ y $padres(2i + 1)$\;
                $C(t) \longleftarrow C(t) \bigcup \{ c_1, c_2 \}$\;
            }    
        }
        
        Evaluar las soluciones de $C(t)$\;
        $P(t+1) \longleftarrow $ Mejores $N$ soluciones de $C(t) \cup P(t)$\;

        \If{$P(t) = P(t+1)$}{
            $d \longleftarrow d - dec$\;
            \If{$d \leq 0$}{
                Inicializar $P(t+1)$ con la mejor solución de $P(t)$ y $N-1$ soluciones aleatorias\;
                Evaluar las nuevas soluciones de $P(t+1)$\;
                $d \longleftarrow$ Media de la distancia de las soluciones de $P(t+1)$\;
                $dec \longleftarrow \tau \cdot$ Distancia máxima de las soluciones de $P(t+1)$\;
            }
        }
        
        $t \longleftarrow t + 1$\;
    }
    \caption{Algoritmo CHC.}
\end{Ualgorithm}

\subsection{Ejemplos}

Cabe destacar que los algoritmos genéticos GGA y CHC han logrado romper el criptosistema de McEliece hasta una longitud de $n = 128$. Para ilustrar el funcionamiento de ambos algoritmos, a continuación vamos a mostrar un ejemplo de sus ejecuciones, en el que intentaremos vulnerar la seguridad del criptosistema de McEliece para dicha longitud.

\begin{exampleth}
    Sea $\mathbb{F}_{2^{7}}$ el cuerpo finito de $128$ elementos y sea $a$ un elemento de dicho cuerpo. Tomando $n = 128$, vamos a calcular un polinomio irreducible y mónico aleatorio de grado $8$:

    \begin{lstlisting}[gobble=4]
        sage: n = 128
        sage: q = 7
        sage: F = GF(2)
        sage: L = GF(2^q)
        sage: a = L.gen()
        sage: R.<x> = L[]
        sage: g = R.random_element(8)
        sage: while g.is_irreducible() == False:
        +         g = R.random_element(8)
        sage: g = g*g.leading_coefficient()^-1
        sage: g
        > x^8 + (z7^6 + z7^5 + z7^2 + z7)*x^7 + x^6 + (z7^5 + z7^4 + z7^2 +
          1)*x^5 + (z7^2 + z7)*x^4 + x^3 + (z7^6 + z7^5 + z7^2 + z7 + 1)*x^2 + 
          (z7^5 + z7^4 + z7^3)*x + z7^3
        \end{lstlisting}
    
    
    Podemos definir el criptosistema de McEliece a partir de estos parámetros con las siguientes órdenes:

    \begin{lstlisting}[gobble=4]
    sage: ME = McEliece(n, q, g); ME
    > McEliece cryptosystem over [128, 72] Goppa code
    \end{lstlisting}

    Ahora, encriptamos el siguiente mensaje:
    \begin{align}
        message := (&1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, \notag\\
                    &0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1), \label{message}
    \end{align}
    que posteriormente averiguaremos.

    \begin{lstlisting}[gobble=4]
    sage: message = vector(F, [1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,
    +     0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 
    +     0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 
    +     1, 0, 1, 1, 0, 0, 0, 0, 1, 1])
    sage: encrypted_message = ME.encrypt(message)
    \end{lstlisting}

    El método \texttt{encrypt()} cifra el mensaje $message$ multiplicándolo por la clave pública $PK$ y añadiéndole un error aleatorio $e$ al resultado.

    A continuación, añadimos una fila a la clave pública $PK$ que contendrá el mensaje encriptado, llamaremos a esta matriz $G$.

    \begin{lstlisting}[gobble=4]
    sage: PK = ME.get_public_key()
    sage: G = PK.stack(encrypted_message)
    \end{lstlisting}

    La matriz $G$ define un código lineal que tiene una distancia mínima $t = \gr(g) = 8$, y cuyo peso mínimo se obtiene en una única palabra: el error $e$. Para averiguar dicho error, debemos ejecutar los algoritmos genéticos GGA y CHC, los cuales nos darán una permutación $p$ con fitness $t$.

    Primero, vamos a ejecutar el algoritmo genético GGA para un tamaño de población $N = 60$, con probabilidad de cruce $p_c = 0.8$, con un máximo de evaluaciones de $max\_reinit = 30$ y con un fitness mínimo igual a $min\_fitness = 8$. 
    
    \begin{lstlisting}[gobble=4]
    sage: p, f = GGA(G, 60, 0.8, 30, 8)
    \end{lstlisting}

    Obtenemos una permutación $p$ que, tras aplicarla, existirá una fila con fitness mínimo $f = 8$ a partir de la cual podremos obtener el error. Por tanto, primero debemos calcular la matriz $P$ asociada a la permutación $p$, aplicársela a la matriz generadora $G$ y obtener la matriz escalonada reducida del resultado $M$:

    \begin{lstlisting}[gobble=4]
    sage: P = permutation_matrix(p)
    sage: M = (G*P).rref()
    \end{lstlisting}

    Obtenemos ahora la fila de la matriz $M$ que tenga peso $f$:

    \begin{lstlisting}[gobble=4]
    sage: for row in M:
    +         if fitness_vector(row) == f:
    +             v = vector(GF(2), row)
    +             break
    \end{lstlisting}
    
    Ahora ya podemos obtener el vector error si deshacemos la permutación al vector $v$ que acabamos de calcular:

    \begin{lstlisting}[gobble=4]
    sage: e = v * P^(-1)
    \end{lstlisting}

    Una vez obtenido el error, se lo restamos al criptograma y resolvemos el sistema $y - e = mPK$,

    \begin{lstlisting}[gobble=4]
    sage: z = encrypted_message - e
    sage: m = PK.solve_left(z)
    sage: m
    >  (1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 
        1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 
        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1)
    sage: m == message
    > True
    \end{lstlisting}

    Observamos que el mensaje $m$ que obtenemos coincide con el mensaje original \eqref{message}. Por lo que hemos conseguido romper el criptosistema de McEliece para $n = 128$ con el algoritmo genético GGA.

    Ahora, ejecutaremos el algoritmo genético CHC. Este algoritmo lo ejecutaremos para un tamaño de población $N = 60$, con $tau = 0.7$ y con un fitness mínimo igual a $min\_fitness = 8$. Una vez ejecutado dicho algoritmo, los pasos son análogos.

    \begin{lstlisting}[gobble=4]
    sage: p, f = CHC(G, 350, 0.8, 8)
    sage: P = permutation_matrix(p)
    sage: M = (G*P).rref()
    sage: for row in M:
    +         if fitness_vector(row) == f:
    +             v = vector(GF(2), row)
    +             break
    sage: e = v * P^(-1)
    \end{lstlisting}

    Una vez obtenido el error, se lo restamos al criptograma y resolvemos el sistema $y - e = mPK$,

    \begin{lstlisting}[gobble=4]
    sage: z = encrypted_message - e
    sage: m = PK.solve_left(z)
    sage: m
    >  (1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,
        1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 
        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1)
    sage: m == message
    > True
    \end{lstlisting}

    Observamos que, igualmente, el mensaje $m$ que obtenemos coincide con el mensaje original \eqref{message}. Por lo que hemos conseguido romper el criptosistema de McEliece para $n = 128$ con el algoritmo genético CHC.
\end{exampleth}